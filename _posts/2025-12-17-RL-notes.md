---
layout: single
title: Notes on NLP
---


---
layout: single
title: Notes on Reinforcement Learning
---

Comprehensive study notes organized by lecture topic (MDPs, planning/control, policy optimization, exploration, and imitation learning). Work In Progress.

## Contents

1. [Introduction to RL](#introduction-to-rl)
2. [MDPs and Bellman Equations](#mdps-and-bellman-equations)
3. [MDPs, Optimal Policies, and Value Iteration](#mdps-optimal-policies-and-value-iteration)
4. [Policy Iteration and Dynamic Programming](#policy-iteration-and-dynamic-programming)
5. [Continuous Control](#continuous-control)
6. [Linear Quadratic Regulation](#linear-quadratic-regulation)
7. [Nonlinear Control](#nonlinear-control)
8. [Limitations in Control and Observation](#limitations-in-control-and-observation)
9. [Prediction and Estimation](#prediction-and-estimation)
10. [Model-based RL](#model-based-rl)
11. [February Break](#february-break)
12. [Approximate and Conservative Policy Iteration](#approximate-and-conservative-policy-iteration)
13. [Supervision via Bellman](#supervision-via-bellman)
14. [Optimization Background](#optimization-background)
15. [Policy Optimization: Random Search and Policy Gradient](#policy-optimization-random-search-and-policy-gradient)
16. [Policy Optimization: Trust Region and Natural PG](#policy-optimization-trust-region-and-natural-pg)
17. [Prelim Review](#prelim-review)
18. [Exploration: Multi-Armed Bandits](#exploration-multi-armed-bandits)
19. [Upper Confidence Bound Algorithm](#upper-confidence-bound-algorithm)
20. [Contextual Bandits](#contextual-bandits)
21. [Linear Contextual Bandits](#linear-contextual-bandits)
22. [Exploration in MDPs](#exploration-in-mdps)
23. [Imitation Learning with BC](#imitation-learning-with-bc)
24. [Interactive Imitation Learning](#interactive-imitation-learning)
25. [Inverse RL](#inverse-rl)

---

## Introduction to RL



## MDPs and Bellman Equations



## MDPs, Optimal Policies, and Value Iteration



## Policy Iteration and Dynamic Programming



## Continuous Control



## Linear Quadratic Regulation



## Nonlinear Control



## Limitations in Control and Observation



## Prediction and Estimation



## Model-based RL



## February Break



## Approximate and Conservative Policy Iteration



## Supervision via Bellman



## Optimization Background



## Policy Optimization: Random Search and Policy Gradient



## Policy Optimization: Trust Region and Natural PG



## Prelim Review



## Exploration: Multi-Armed Bandits



## Upper Confidence Bound Algorithm



## Contextual Bandits



## Linear Contextual Bandits



## Exploration in MDPs



## Imitation Learning with BC



## Interactive Imitation Learning



## Inverse RL


